{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Efficient Algorithms: Suffix Array Construction\n",
    "\n",
    "Instructions\n",
    "Erstellen Sie ein Suffix-Array für das angehängte e-Book von https://www.gutenberg.org/. Das File ist in UTF-8 codiert. Achten Sie auf ein geschicktes Wort-Ende-Zeichen, das nicht als Buchstabe im Buch vorkommt und kleiner als alle Buchstaben im Buch ist. Tipp: Entfernen Sie vor der Analyse alle Zeilenumbrüche, überflüssigen White-Spaces und verbinden Sie getrennten Wörter zu einem Wort. \n",
    "Versuchen Sie zunächst das Suffix-Array durch Brute-Force-Sortieren in Python zu erstellen. \n",
    "(1) Alle Suffixe in einem Array erstellen. \n",
    "(2) Wort-Ende Zeichen hinzufügen. \n",
    "(2) Mit der sort()-Funktion sortieren, sodass die lexikographische Sortierung erreicht wird. Messen Sie die Laufzeit Ihres Codes mit dem Python time-Modul 5 mal und bilden Sie einen Mittelwert.\n",
    "Entwickeln Sie einen alternative hoffentlich schnellere Lösung die nicht auf bekannten Suffix-Array-Konstruktionsalgorithmen (Mamber & Meyers, Ko & Aluru, Kairkkainen & Sanders ...) beruht und auch keine diesbezüglichen Suffix-Array-Libraries benutzt. Entwickeln Sie stattdessen Ihre eigene (heuristische) Idee und wiederholen Sie die Analyseschritte wie beim Brute-Force Algorithmus. Es macht nichts, wenn Ihre Idee praktisch nicht schneller ist als der Brute-Force Algorithmus, solange es einen logische Argumentation gibt, warum Ihre Idee besser sein sollte.\n",
    "\n",
    "Abgabe (PDF Dokument):\n",
    "Python Code für Brute-Force Algorithms (3P)\n",
    "Durchschnittliche Laufzeit (Mittelwert über 5 Durchläufe) für Brute-Force Algorithmus (2P)\n",
    "Python Code für Ihren Algorithmus (10P)\n",
    "Beschreibung der Optimierungs-Idee für Ihren Algorithmus (10P)\n",
    "Durchschnittliche Laufzeit (Mittelwert über 5 Durchläufe) für Ihren Algorithmus (2P)\n",
    "Argumentation warum Ihr Algorithmus praktische schneller/langsamer ist, als Brute-Force (10P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def getAllWords():\n",
    "    all_words_cleaned=[]\n",
    "\n",
    "    with open('./TomSawyerCompleteGutenberg.txt', encoding='utf-8-sig') as f:\n",
    "        for line in f:\n",
    "\n",
    "            # split on space and line endings\n",
    "            splittet_line=line.split()\n",
    "            \n",
    "            wordIndex = 0\n",
    "\n",
    "            replacedSpecialChars = []\n",
    "            for wordIndex in range(len(splittet_line)):\n",
    "                # find all special chars and replace them with nothign\n",
    "                newWord = re.sub(\"[^A-Za-z0-9]+\", \"\", splittet_line[wordIndex])\n",
    "                # make all words lowercase\n",
    "                newWord = newWord.lower()\n",
    "                replacedSpecialChars.append(newWord)\n",
    "\n",
    "                wordIndex+=1\n",
    "            if(len(replacedSpecialChars)>0):\n",
    "                for word in replacedSpecialChars:\n",
    "                    all_words_cleaned.append(word)\n",
    "    return all_words_cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate suffix array\n",
    "\n",
    "def createSuffixArr(all_words_cleaned):\n",
    "    suffix_arr = []\n",
    "\n",
    "    #generate suffix arr\n",
    "    for word in all_words_cleaned:\n",
    "        charIndex = 0\n",
    "        for charIndex in range(len(word)):\n",
    "            suffix = word[charIndex:]\n",
    "            suffix +=\"$\"\n",
    "            suffix_arr.append(suffix)\n",
    "\n",
    "    return suffix_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.34999990463256836 seconds ----\n",
      "--- 0.34399986267089844 seconds ----\n",
      "--- 0.3509998321533203 seconds ----\n",
      "--- 0.3530001640319824 seconds ----\n",
      "--- 0.34900760650634766 seconds ----\n",
      "--- 0.34940147399902344 All Runs ----\n"
     ]
    }
   ],
   "source": [
    "##sort suffix array\n",
    "import time\n",
    "\n",
    "i = 0\n",
    "\n",
    "runs = 5\n",
    "\n",
    "\n",
    "allTimesTogehter = 0\n",
    "while i < runs:\n",
    "    start_time = time.time()\n",
    "\n",
    "\n",
    "    allWords = getAllWords()\n",
    "\n",
    "    suffix_array = createSuffixArr(allWords)\n",
    "    suffix_array.sort()\n",
    "    currentTime = time.time()-start_time\n",
    "    allTimesTogehter += currentTime\n",
    "    print(\"--- %s seconds ----\" % (currentTime))\n",
    "    i +=1\n",
    "\n",
    "print(\"--- %s All Runs ----\" % (allTimesTogehter/5))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5c3b02fa24688d32a1d09351b7f8eac82a87272ad081601c73caead00a8e1fc4"
  },
  "kernelspec": {
   "display_name": "Python 2.7.13 32-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
